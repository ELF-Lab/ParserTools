<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>csv2fst.lexc_path API documentation</title>
<meta name="description" content="Functions and classes for converting a morphological paradigm
spreadsheet row into one or more paths in a lexc file." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>csv2fst.lexc_path</code></h1>
</header>
<section id="section-intro">
<p>Functions and classes for converting a morphological paradigm
spreadsheet row into one or more paths in a lexc file.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;Functions and classes for converting a morphological paradigm
   spreadsheet row into one or more paths in a lexc file.

&#34;&#34;&#34;

from sys import stderr
import re
import pandas as pd
from collections import namedtuple
from log import warn

MAXFORMS=100
&#34;&#34;&#34;Maximum number of alternate forms for a single analysis in the
    spreadsheets.

&#34;&#34;&#34;

PREFIX_BOUNDARY = &#34;&lt;&lt;&#34;
&#34;&#34;&#34;Morpheme boundary between prefix and stem.&#34;&#34;&#34;

SUFFIX_BOUNDARY = &#34;&gt;&gt;&#34;
&#34;&#34;&#34;Morpheme boundary between stem and suffix.&#34;&#34;&#34;

LexcEntry = namedtuple(&#34;LexcEntry&#34;,
                       [&#34;lexicon&#34;,
                        &#34;analysis&#34;,
                        &#34;surface&#34;,
                        &#34;next_lexicon&#34;])
LexcEntry.__doc__ = \
&#34;&#34;&#34;LexcEntry represents a Lexc sublexicon entry like:

    ```
    LEXICON Lex
       upper:lower NextLex ;
    ```

    which corresponds to: 

    ```
    entry = LexcEntry(&#34;Lex&#34;, &#34;upper&#34;, &#34;lower&#34;, &#34;NextLex&#34;)
    ```

    Access features as:

    ```
    entry.lexicon, entry.analysis, entry.surface, entry.next_lexicon
    ```
&#34;&#34;&#34;

SplitForm = namedtuple(&#34;SplitForm&#34;,
                       [&#34;prefix&#34;,
                        &#34;stem&#34;,
                        &#34;suffix&#34;])
SplitForm.__doc__ = \
&#34;&#34;&#34;SplitForm represents an inflected word form consisting of a
    prefix, stem and suffix:

    ```
    &#34;pre&lt;&lt;st&gt;&gt;suf&#34;
    ```

    corresponds to:

    ```
    split_form = SplitForm(&#34;pre&#34;,&#34;st&#34;,&#34;suf&#34;)
    ```

    Access features as:

    ```
    split_form.prefix, split_form.stem, split_form.suffix
    ```

&#34;&#34;&#34;


def entry2str(entry:LexcEntry) -&gt; str:
    &#34;&#34;&#34;Return the string representation of a LexcEntry object. When the
        upper and lower string are identical, the function will
        collapse them into one entry. If the upper and lower string
        are empty, only the continuation lexicon is retained.  This
        enhances readability of the lexc file.

    &#34;&#34;&#34;
    if entry.analysis == entry.surface:
        if entry.analysis == &#34;0&#34;:
            return f&#34;{entry.next_lexicon} ;&#34;
        else:
            return f&#34;{entry.analysis} {entry.next_lexicon} ;&#34;
    else:
        return f&#34;{entry.analysis}:{entry.surface} {entry.next_lexicon} ;&#34;

def escape(symbol:str) -&gt; str:
    &#34;&#34;&#34;Escape lexc special characters using a `%`. If the character is
        already escaped using `%`, don&#39;t add a second escape
        symbol. This function will escape symbols in the range
        `[!%&lt;&gt;0/#; ]`

    &#34;&#34;&#34;
    return re.sub(&#34;(?&lt;!%)([!%&lt;&gt;0/#; ])&#34;,r&#34;%\1&#34;,symbol)

def split_form(form:str) -&gt; SplitForm:
    &#34;&#34;&#34;Split a form `prefix&lt;&lt;stem&gt;&gt;suffix` (e.g. found in the column
        `Form1Split` in paradigm spreadsheets) at morpheme boundaries
        (`&lt;&lt;` and `&gt;&gt;`). If either boundary is missing, the function
        will add one at the start and end and issue a warning. A
        SplitForm object is returned.

    &#34;&#34;&#34;
    # re.split results in a 5-element array [prefix, &#34;&lt;&lt;&#34;, stem, &#34;&gt;&gt;&#34;,
    # suffix]
    if not PREFIX_BOUNDARY in form:
        form = PREFIX_BOUNDARY + form
        warn(f&#34;Invalid form: {form}. Appending morpheme boundary &#39;{PREFIX_BOUNDARY}&#39; at the start.&#34;)    
    if not SUFFIX_BOUNDARY in form:
        form += SUFFIX_BOUNDARY
        warn(f&#34;Invalid form: {form}. Appending morpheme boundary &#39;{SUFFIX_BOUNDARY}&#39; at the end.&#34;)
    form = re.split(f&#34;({PREFIX_BOUNDARY}|{SUFFIX_BOUNDARY})&#34;, form)
    if len(form) != 5:
        raise ValueError(f&#34;Invalid form: {orig_form}. Split: {form}&#34;)
    return SplitForm(escape(form[0]), escape(form[2]), escape(form[4]))


class LexcPath:
    &#34;&#34;&#34;The LexcPath class represents a path in a lexc file from a root
       lexicon like `VerbRoot` or `NounRoot` to the terminal lexicon
       `#`. This path corresponds to a list of LexcEntry objects: 

       ``` [entry_1, entry_2, ..., entry_n] ``` 

       where `entry_1.lexicon` is the root lexicon, 
       `entry_i+1.lexicon = entry_i.next_lexicon` and
       `entry_n.next_lexicon = &#34;#&#34;`

       A lexc file can be thought of as a union of this type of paths.

       A LexcPath object encodes all the information on one spreadsheet
       row (e.g. a row in VTA_IND.csv in the OjibweMorph repo). Thus
       the path can contain multiple surface forms (Surface1Form,
       Surface2Form, ...). LexcPath can therefore encode multiple
       sub-lexicon entries e.g. corresponding to alternative endings of
       an inflected form.
    &#34;&#34;&#34;

    multichar_symbols:set[str] = set()
    &#34;&#34;&#34;Multichar symbols (across all lexc files) are stored in this static
       set

    &#34;&#34;&#34;

    @classmethod
    def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
        &#34;&#34;&#34;This function adds all multicharacter symbols speficied in a
           configuration file + morpheme boundaries into the
           `multichar_symbols` set.

        &#34;&#34;&#34;
        cls.multichar_symbols.update(map(escape,conf[&#34;multichar_symbols&#34;]))
        cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
        cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))
        
    @classmethod
    def get_prefix_flags(cls, prefix:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get P and R flag diacritics like @P.Prefix.NI@ which
           determine valid combinations of prefixes and suffixes.

           The flag diacritics will be added to `multichar_symbols`.

        &#34;&#34;&#34;
        prefix = &#34;NONE&#34; if prefix == &#34;&#34; else prefix.upper()
        pflag, rflag = f&#34;@P.Prefix.{prefix}@&#34;, f&#34;@R.Prefix.{prefix}@&#34;
        cls.multichar_symbols.update([pflag, rflag])
        return pflag, rflag

    @classmethod
    def get_paradigm_flags(cls, paradigm:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get P and R flag diacritics for a given paradigm like VTA.

           The flag diacritics will be added to `multichar_symbols`.

        &#34;&#34;&#34;        
        pflag, rflag = f&#34;@P.Paradigm.{paradigm}@&#34;, f&#34;@R.Paradigm.{paradigm}@&#34;
        cls.multichar_symbols.update([pflag, rflag])        
        return pflag, rflag
    
    def get_order_flag(self) -&gt; tuple[str]:
        &#34;&#34;&#34;Get a U flag matching the order of this LexcPath: Ind, Cnj or
           Other (in case of imperative or other unspecified order).

           The flag diacritic will be added to `multichar_symbols`.
        &#34;&#34;&#34;
        order = &#34;Other&#34;
        if &#34;+Ind&#34; in self.tags:
            order = &#34;Ind&#34;
        elif &#34;+Cnj&#34; in self.tags:
            order = &#34;Cnj&#34;
        flag = f&#34;@U.Order.{order}@&#34;
        LexcPath.multichar_symbols.update([flag])
        return order, flag

    def __init__(self, row:pd.core.series.Series, conf:dict, regular:bool):
        &#34;&#34;&#34;Initialize this LexcPath using the configuration file conf and a
        spreadsheet row. The boolean parameter regular determines whether this
        is treated as a regular form (which should have morpheme boundaries
        and undergo phonological rules) or an irregular form which is stored
        in the lexc file in verbatim.

        All morphological features like &#34;+VTA&#34;, &#34;+Ind&#34; and &#34;+1SgSubj&#34;
        apperaing on the spreadsheet row will be added to
        multichar_symbols.

        &#34;&#34;&#34;
        self.root_lexicon = conf[&#34;root_lexicon&#34;]
        self.row = row
        self.conf = conf
        self.regular = regular
        self.paradigm = row[&#34;Paradigm&#34;]
        self.klass = row[&#34;Class&#34;]
        self.lemma = escape(row[&#34;Lemma&#34;])
        self.stem = escape(row[&#34;Stem&#34;])
        self.tags = [escape(f&#34;+{row[feat]}&#34;)
                     for feat in conf[&#34;morph_features&#34;]
                     if (row[feat] != conf[&#34;missing_tag_marker&#34;] and
                         row[feat] != &#34;&#34;)]
        self.harvest_multichar_symbols()

        try:
            self.read_forms(row, conf)
        except ValueError as e:
            warn(e)
            
    def harvest_multichar_symbols(self) -&gt; None:
        &#34;&#34;&#34;Add all morphological features like &#34;+VTA&#34;, &#34;+Ind&#34; and &#34;+1SgSubj&#34;
           from this path to the multichar_symbols set

        &#34;&#34;&#34;
        for tag in self.tags:
            LexcPath.multichar_symbols.add(tag)

    def read_forms(self, row:pd.core.series.Series, conf:dict) -&gt; None:
        &#34;&#34;&#34;Read all forms on the given dataframe row. Store both the plain
           surface form and segmented form.

        &#34;&#34;&#34;
        def get_form_indices() -&gt; list[int]:
            # Return all indices i which are associated with a surface
            # form on this row, i.e. i where Form{i}Surface is a
            # column on the row and the form in that column is
            # non-empty.
            missing = conf[&#34;missing_form_marker&#34;]
            return [i for i in range(MAXFORMS) if f&#34;Form{i}Surface&#34; in row and
                                                  not row[f&#34;Form{i}Surface&#34;] in [missing, &#34;&#34;]]
        
        self.forms = [(row[f&#34;Form{i}Surface&#34;], split_form(row[f&#34;Form{i}Split&#34;]))
                      for i in get_form_indices()]
        if len(self.forms) == 0:
            raise ValueError(f&#34;No surface forms given for row: {row.to_dict()}&#34;)
        
    def get_lexc_paths(self) -&gt; list[list[LexcEntry]]:
        &#34;&#34;&#34;Convert this path into a list of lexc lexicon paths starting
           at a person prefix lexicon (this could be VTA_Prefix, NA_Prefix, 
           etc.) and ending in the terminal lexicon #. Each path is a 
           sequence of lexc sublexicon entries.

           There will be one list-element for each surface form (note that 
           there may be several surface forms Form1Surface, Form2Surface, 
           ...).

           For inflected forms of regular lexemes, our paths will look
           like this (here, for the example analysis and form
           aaba&#39;+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba&#39;wigosiinaadogenan):

           ```
              ! Person prefix lexicon for nouns and verbs. For all other 
              ! word classes the prefix is always empty (@P.Prefix.NONE@)
              LEXICON VTA_Prefix
              @P.Prefix.NI@:@P.Prefix.NI@ni VTA_PrefixBoundary ;

              ! Morpheme boundary for person prefix. Note that we can jump
              ! to a preverb lexicon here. For all word classes apart from
              ! nouns and verbs, we jump directly to the a stem lexicon.
              LEXICON VTA_PrefixBoundary
              0:%&lt;%&lt; PreverbRoot ;
        
              ! After adding preverbs, we return to this lexicon. Need to
              ! match the correct paradigm here
              LEXICON VerbStems
              @R.Paradigm.VTA@ VTA_Stems ;

              ! Stem lexicon. aaba&#39; belongs to the VTA_C inflection class,
              ! so we continue to the VTA_C suffix boundary lexicon.
              LEXICON VTA_Stems
              aaba&#39;:aaba&#39;w VTA_Class=VTA_C_Boundary ;

              ! Suffix boundary
              LEXICON VTA_Class=VTA_C_Boundary
              0:%&gt;%&gt; VTA_Class=VTA_C_Flags ;

              ! This sublexicon makes sure that we get the correct 
              ! combination of person prefix (&#34;ni-&#34; in this case) and ending.
              ! The combinatorics is handled by matching the value of the 
              ! feature Prefix (NI in this case).
              LEXICON VTA_Class=VTA_C_Flags
              @R.Prefix.NI@ VTA_Class=VTA_C_Flags_Prefix=NI ;

              ! We need to match the correct order here
              LEXICON VTA_Class=VTA_C_Flags_Prefix=NI ;
              @U.Order.Ind@ VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings ;

              ! This lexicon enumerates endings for the inflection class
              ! VAT_C which correspond to person prefix &#34;ni-&#34; and order Ind.
              LEXICON VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings
              +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;
           ```

           For inflected forms of irregular lexemes, our paths become
           very simple. We just enumerate the entire form as one
           chunk without morpheme boundaries. This effectively prevents any
           phonological rules from applying, which is exactly what we want
           for irregular lexemes:

           ```
              LEXICON ROOT
              VTA_Irregular ;

              LEXICON VTA_Irregular
              izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;
           ```
        &#34;&#34;&#34;
        paths = []
        paradigm = self.paradigm
        klass = self.klass
        for surface, parts in self.forms:
            if self.regular:
                # Flag diacritics which:
                # (1) control combinations of person prefix and inflectional ending,
                # (2) check that we&#39;ve got the correct paradigm (this is needed to
                #     make sure that return to the correct paradigm after adding
                #     preverbs), and
                # (3) check the order (we track this because subordinate preverbs
                #     and the changed-conjunct marker require conjunct order and some
                #     preverbs have distinct independent and conjunct order surface
                #     forms) 
                set_prefix_flag, check_prefix_flag = LexcPath.get_prefix_flags(parts.prefix)
                _, check_paradigm_flag = LexcPath.get_paradigm_flags(paradigm)
                order, check_order_flag = self.get_order_flag()

                # The person prefix for this form
                prefix = &#34;NONE&#34; if parts.prefix == &#34;&#34; else parts.prefix.upper()

                # Continuation lexicons needed on this path
                person_prefix_lexicon = f&#34;{paradigm}_Prefix&#34;
                morpheme_boundary_lexicon = f&#34;{paradigm}_PrefixBoundary&#34;
                preverb_lexicon = (self.conf[&#34;prefix_root&#34;] # This can also be the prenoun lexicon depending on paradigm
                                   if &#34;prefix_root&#34; in self.conf
                                   else None)
                pos_stem_lexicon = f&#34;{self.conf[&#39;pos&#39;]}Stems&#34; # E.g. VerbStems
                paradigm_stem_lexicon = f&#34;{paradigm}_Stems&#34; # E.g. VTA_Stems
                inflection_class_lexicon = f&#34;{paradigm}_Class={klass}_Boundary&#34;
                check_prefix_lexicon = f&#34;{paradigm}_Class={klass}_Flags&#34;
                check_order_lexicon = f&#34;{paradigm}_Class={klass}_Flags_Prefix={prefix}&#34;
                ending_lexicon = f&#34;{paradigm}_Class={klass}_Prefix={prefix}_Order={order}_Endings&#34;
                
                path = [
                    LexcEntry(person_prefix_lexicon,
                              set_prefix_flag,
                              set_prefix_flag+parts.prefix,
                              morpheme_boundary_lexicon),
                    LexcEntry(morpheme_boundary_lexicon,
                              &#34;0&#34;,
                              escape(PREFIX_BOUNDARY),
                              preverb_lexicon or pos_stem_lexicon),
                    LexcEntry(pos_stem_lexicon,
                              check_paradigm_flag,
                              check_paradigm_flag,
                              paradigm_stem_lexicon),
                    LexcEntry(paradigm_stem_lexicon,
                              self.lemma,
                              self.stem,
                              inflection_class_lexicon),
                    LexcEntry(inflection_class_lexicon,
                              &#34;0&#34;,
                              escape(SUFFIX_BOUNDARY),
                              check_prefix_lexicon),
                    LexcEntry(check_prefix_lexicon,
                              check_prefix_flag,
                              check_prefix_flag,
                              check_order_lexicon),
                    LexcEntry(check_order_lexicon,
                              check_order_flag,
                              check_order_flag,
                              ending_lexicon),
                    LexcEntry(ending_lexicon,
                              &#34;&#34;.join(self.tags),
                              parts.suffix,
                              &#34;#&#34;)
                ]
                paths.append(path)
            else:
                # Irregular forms are treated as one chunk and simply enumerated.
                paths.append([LexcEntry(f&#34;{paradigm}_Irregular&#34;,
                                        f&#34;{self.lemma}{&#39;&#39;.join(self.tags)}&#34;,
                                        surface,
                                        &#34;#&#34;)])

        return paths

    def extend_lexicons(self, lexicons:dict) -&gt; None:
        &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
        def get_paradigm(s):
            return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
        for path in self.get_lexc_paths():
            paradigm = get_paradigm(path[0].lexicon)
            p_paradigm_flag, _ = LexcPath.get_paradigm_flags(paradigm)
            lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                      p_paradigm_flag,
                                                      p_paradigm_flag,
                                                      path[0].lexicon))
            for lexc_entry in path:
                if not lexc_entry.lexicon in lexicons:
                    lexicons[lexc_entry.lexicon] = set()
                lexicons[lexc_entry.lexicon].add(lexc_entry)
        
    def __str__(self):        
        paths = self.get_lexc_paths()
        res = &#34;&#34;
        for path in paths:
            for lexc_entry in path:
                res += f&#34;{lexc_entry}\n&#34;
            res += &#34;----\n&#34;
        return res

    def __hash__(self):
        return hash(str(self))</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="csv2fst.lexc_path.MAXFORMS"><code class="name">var <span class="ident">MAXFORMS</span></code></dt>
<dd>
<div class="desc"><p>Maximum number of alternate forms for a single analysis in the
spreadsheets.</p></div>
</dd>
<dt id="csv2fst.lexc_path.PREFIX_BOUNDARY"><code class="name">var <span class="ident">PREFIX_BOUNDARY</span></code></dt>
<dd>
<div class="desc"><p>Morpheme boundary between prefix and stem.</p></div>
</dd>
<dt id="csv2fst.lexc_path.SUFFIX_BOUNDARY"><code class="name">var <span class="ident">SUFFIX_BOUNDARY</span></code></dt>
<dd>
<div class="desc"><p>Morpheme boundary between stem and suffix.</p></div>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="csv2fst.lexc_path.entry2str"><code class="name flex">
<span>def <span class="ident">entry2str</span></span>(<span>entry: <a title="csv2fst.lexc_path.LexcEntry" href="#csv2fst.lexc_path.LexcEntry">LexcEntry</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return the string representation of a LexcEntry object. When the
upper and lower string are identical, the function will
collapse them into one entry. If the upper and lower string
are empty, only the continuation lexicon is retained.
This
enhances readability of the lexc file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def entry2str(entry:LexcEntry) -&gt; str:
    &#34;&#34;&#34;Return the string representation of a LexcEntry object. When the
        upper and lower string are identical, the function will
        collapse them into one entry. If the upper and lower string
        are empty, only the continuation lexicon is retained.  This
        enhances readability of the lexc file.

    &#34;&#34;&#34;
    if entry.analysis == entry.surface:
        if entry.analysis == &#34;0&#34;:
            return f&#34;{entry.next_lexicon} ;&#34;
        else:
            return f&#34;{entry.analysis} {entry.next_lexicon} ;&#34;
    else:
        return f&#34;{entry.analysis}:{entry.surface} {entry.next_lexicon} ;&#34;</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.escape"><code class="name flex">
<span>def <span class="ident">escape</span></span>(<span>symbol: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Escape lexc special characters using a <code>%</code>. If the character is
already escaped using <code>%</code>, don't add a second escape
symbol. This function will escape symbols in the range
<code>[!%&lt;&gt;0/#; ]</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def escape(symbol:str) -&gt; str:
    &#34;&#34;&#34;Escape lexc special characters using a `%`. If the character is
        already escaped using `%`, don&#39;t add a second escape
        symbol. This function will escape symbols in the range
        `[!%&lt;&gt;0/#; ]`

    &#34;&#34;&#34;
    return re.sub(&#34;(?&lt;!%)([!%&lt;&gt;0/#; ])&#34;,r&#34;%\1&#34;,symbol)</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.split_form"><code class="name flex">
<span>def <span class="ident">split_form</span></span>(<span>form: str) ‑> <a title="csv2fst.lexc_path.SplitForm" href="#csv2fst.lexc_path.SplitForm">SplitForm</a></span>
</code></dt>
<dd>
<div class="desc"><p>Split a form <code>prefix&lt;&lt;stem&gt;&gt;suffix</code> (e.g. found in the column
<code>Form1Split</code> in paradigm spreadsheets) at morpheme boundaries
(<code>&lt;&lt;</code> and <code>&gt;&gt;</code>). If either boundary is missing, the function
will add one at the start and end and issue a warning. A
SplitForm object is returned.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_form(form:str) -&gt; SplitForm:
    &#34;&#34;&#34;Split a form `prefix&lt;&lt;stem&gt;&gt;suffix` (e.g. found in the column
        `Form1Split` in paradigm spreadsheets) at morpheme boundaries
        (`&lt;&lt;` and `&gt;&gt;`). If either boundary is missing, the function
        will add one at the start and end and issue a warning. A
        SplitForm object is returned.

    &#34;&#34;&#34;
    # re.split results in a 5-element array [prefix, &#34;&lt;&lt;&#34;, stem, &#34;&gt;&gt;&#34;,
    # suffix]
    if not PREFIX_BOUNDARY in form:
        form = PREFIX_BOUNDARY + form
        warn(f&#34;Invalid form: {form}. Appending morpheme boundary &#39;{PREFIX_BOUNDARY}&#39; at the start.&#34;)    
    if not SUFFIX_BOUNDARY in form:
        form += SUFFIX_BOUNDARY
        warn(f&#34;Invalid form: {form}. Appending morpheme boundary &#39;{SUFFIX_BOUNDARY}&#39; at the end.&#34;)
    form = re.split(f&#34;({PREFIX_BOUNDARY}|{SUFFIX_BOUNDARY})&#34;, form)
    if len(form) != 5:
        raise ValueError(f&#34;Invalid form: {orig_form}. Split: {form}&#34;)
    return SplitForm(escape(form[0]), escape(form[2]), escape(form[4]))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="csv2fst.lexc_path.LexcEntry"><code class="flex name class">
<span>class <span class="ident">LexcEntry</span></span>
<span>(</span><span>lexicon, analysis, surface, next_lexicon)</span>
</code></dt>
<dd>
<div class="desc"><p>LexcEntry represents a Lexc sublexicon entry like:</p>
<pre><code>LEXICON Lex
   upper:lower NextLex ;
</code></pre>
<p>which corresponds to: </p>
<pre><code>entry = LexcEntry(&quot;Lex&quot;, &quot;upper&quot;, &quot;lower&quot;, &quot;NextLex&quot;)
</code></pre>
<p>Access features as:</p>
<pre><code>entry.lexicon, entry.analysis, entry.surface, entry.next_lexicon
</code></pre></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcEntry.analysis"><code class="name">var <span class="ident">analysis</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.lexicon"><code class="name">var <span class="ident">lexicon</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.next_lexicon"><code class="name">var <span class="ident">next_lexicon</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 3</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.surface"><code class="name">var <span class="ident">surface</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
</dl>
</dd>
<dt id="csv2fst.lexc_path.LexcPath"><code class="flex name class">
<span>class <span class="ident">LexcPath</span></span>
<span>(</span><span>row: pandas.core.series.Series, conf: dict, regular: bool)</span>
</code></dt>
<dd>
<div class="desc"><p>The LexcPath class represents a path in a lexc file from a root
lexicon like <code>VerbRoot</code> or <code>NounRoot</code> to the terminal lexicon
<code>#</code>. This path corresponds to a list of LexcEntry objects: </p>
<p><code>[entry_1, entry_2, ..., entry_n]</code> </p>
<p>where <code>entry_1.lexicon</code> is the root lexicon,
<code>entry_i+1.lexicon = entry_i.next_lexicon</code> and
<code>entry_n.next_lexicon = "#"</code></p>
<p>A lexc file can be thought of as a union of this type of paths.</p>
<p>A LexcPath object encodes all the information on one spreadsheet
row (e.g. a row in VTA_IND.csv in the OjibweMorph repo). Thus
the path can contain multiple surface forms (Surface1Form,
Surface2Form, &hellip;). LexcPath can therefore encode multiple
sub-lexicon entries e.g. corresponding to alternative endings of
an inflected form.</p>
<p>Initialize this LexcPath using the configuration file conf and a
spreadsheet row. The boolean parameter regular determines whether this
is treated as a regular form (which should have morpheme boundaries
and undergo phonological rules) or an irregular form which is stored
in the lexc file in verbatim.</p>
<p>All morphological features like "+VTA", "+Ind" and "+1SgSubj"
apperaing on the spreadsheet row will be added to
multichar_symbols.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LexcPath:
    &#34;&#34;&#34;The LexcPath class represents a path in a lexc file from a root
       lexicon like `VerbRoot` or `NounRoot` to the terminal lexicon
       `#`. This path corresponds to a list of LexcEntry objects: 

       ``` [entry_1, entry_2, ..., entry_n] ``` 

       where `entry_1.lexicon` is the root lexicon, 
       `entry_i+1.lexicon = entry_i.next_lexicon` and
       `entry_n.next_lexicon = &#34;#&#34;`

       A lexc file can be thought of as a union of this type of paths.

       A LexcPath object encodes all the information on one spreadsheet
       row (e.g. a row in VTA_IND.csv in the OjibweMorph repo). Thus
       the path can contain multiple surface forms (Surface1Form,
       Surface2Form, ...). LexcPath can therefore encode multiple
       sub-lexicon entries e.g. corresponding to alternative endings of
       an inflected form.
    &#34;&#34;&#34;

    multichar_symbols:set[str] = set()
    &#34;&#34;&#34;Multichar symbols (across all lexc files) are stored in this static
       set

    &#34;&#34;&#34;

    @classmethod
    def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
        &#34;&#34;&#34;This function adds all multicharacter symbols speficied in a
           configuration file + morpheme boundaries into the
           `multichar_symbols` set.

        &#34;&#34;&#34;
        cls.multichar_symbols.update(map(escape,conf[&#34;multichar_symbols&#34;]))
        cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
        cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))
        
    @classmethod
    def get_prefix_flags(cls, prefix:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get P and R flag diacritics like @P.Prefix.NI@ which
           determine valid combinations of prefixes and suffixes.

           The flag diacritics will be added to `multichar_symbols`.

        &#34;&#34;&#34;
        prefix = &#34;NONE&#34; if prefix == &#34;&#34; else prefix.upper()
        pflag, rflag = f&#34;@P.Prefix.{prefix}@&#34;, f&#34;@R.Prefix.{prefix}@&#34;
        cls.multichar_symbols.update([pflag, rflag])
        return pflag, rflag

    @classmethod
    def get_paradigm_flags(cls, paradigm:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get P and R flag diacritics for a given paradigm like VTA.

           The flag diacritics will be added to `multichar_symbols`.

        &#34;&#34;&#34;        
        pflag, rflag = f&#34;@P.Paradigm.{paradigm}@&#34;, f&#34;@R.Paradigm.{paradigm}@&#34;
        cls.multichar_symbols.update([pflag, rflag])        
        return pflag, rflag
    
    def get_order_flag(self) -&gt; tuple[str]:
        &#34;&#34;&#34;Get a U flag matching the order of this LexcPath: Ind, Cnj or
           Other (in case of imperative or other unspecified order).

           The flag diacritic will be added to `multichar_symbols`.
        &#34;&#34;&#34;
        order = &#34;Other&#34;
        if &#34;+Ind&#34; in self.tags:
            order = &#34;Ind&#34;
        elif &#34;+Cnj&#34; in self.tags:
            order = &#34;Cnj&#34;
        flag = f&#34;@U.Order.{order}@&#34;
        LexcPath.multichar_symbols.update([flag])
        return order, flag

    def __init__(self, row:pd.core.series.Series, conf:dict, regular:bool):
        &#34;&#34;&#34;Initialize this LexcPath using the configuration file conf and a
        spreadsheet row. The boolean parameter regular determines whether this
        is treated as a regular form (which should have morpheme boundaries
        and undergo phonological rules) or an irregular form which is stored
        in the lexc file in verbatim.

        All morphological features like &#34;+VTA&#34;, &#34;+Ind&#34; and &#34;+1SgSubj&#34;
        apperaing on the spreadsheet row will be added to
        multichar_symbols.

        &#34;&#34;&#34;
        self.root_lexicon = conf[&#34;root_lexicon&#34;]
        self.row = row
        self.conf = conf
        self.regular = regular
        self.paradigm = row[&#34;Paradigm&#34;]
        self.klass = row[&#34;Class&#34;]
        self.lemma = escape(row[&#34;Lemma&#34;])
        self.stem = escape(row[&#34;Stem&#34;])
        self.tags = [escape(f&#34;+{row[feat]}&#34;)
                     for feat in conf[&#34;morph_features&#34;]
                     if (row[feat] != conf[&#34;missing_tag_marker&#34;] and
                         row[feat] != &#34;&#34;)]
        self.harvest_multichar_symbols()

        try:
            self.read_forms(row, conf)
        except ValueError as e:
            warn(e)
            
    def harvest_multichar_symbols(self) -&gt; None:
        &#34;&#34;&#34;Add all morphological features like &#34;+VTA&#34;, &#34;+Ind&#34; and &#34;+1SgSubj&#34;
           from this path to the multichar_symbols set

        &#34;&#34;&#34;
        for tag in self.tags:
            LexcPath.multichar_symbols.add(tag)

    def read_forms(self, row:pd.core.series.Series, conf:dict) -&gt; None:
        &#34;&#34;&#34;Read all forms on the given dataframe row. Store both the plain
           surface form and segmented form.

        &#34;&#34;&#34;
        def get_form_indices() -&gt; list[int]:
            # Return all indices i which are associated with a surface
            # form on this row, i.e. i where Form{i}Surface is a
            # column on the row and the form in that column is
            # non-empty.
            missing = conf[&#34;missing_form_marker&#34;]
            return [i for i in range(MAXFORMS) if f&#34;Form{i}Surface&#34; in row and
                                                  not row[f&#34;Form{i}Surface&#34;] in [missing, &#34;&#34;]]
        
        self.forms = [(row[f&#34;Form{i}Surface&#34;], split_form(row[f&#34;Form{i}Split&#34;]))
                      for i in get_form_indices()]
        if len(self.forms) == 0:
            raise ValueError(f&#34;No surface forms given for row: {row.to_dict()}&#34;)
        
    def get_lexc_paths(self) -&gt; list[list[LexcEntry]]:
        &#34;&#34;&#34;Convert this path into a list of lexc lexicon paths starting
           at a person prefix lexicon (this could be VTA_Prefix, NA_Prefix, 
           etc.) and ending in the terminal lexicon #. Each path is a 
           sequence of lexc sublexicon entries.

           There will be one list-element for each surface form (note that 
           there may be several surface forms Form1Surface, Form2Surface, 
           ...).

           For inflected forms of regular lexemes, our paths will look
           like this (here, for the example analysis and form
           aaba&#39;+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba&#39;wigosiinaadogenan):

           ```
              ! Person prefix lexicon for nouns and verbs. For all other 
              ! word classes the prefix is always empty (@P.Prefix.NONE@)
              LEXICON VTA_Prefix
              @P.Prefix.NI@:@P.Prefix.NI@ni VTA_PrefixBoundary ;

              ! Morpheme boundary for person prefix. Note that we can jump
              ! to a preverb lexicon here. For all word classes apart from
              ! nouns and verbs, we jump directly to the a stem lexicon.
              LEXICON VTA_PrefixBoundary
              0:%&lt;%&lt; PreverbRoot ;
        
              ! After adding preverbs, we return to this lexicon. Need to
              ! match the correct paradigm here
              LEXICON VerbStems
              @R.Paradigm.VTA@ VTA_Stems ;

              ! Stem lexicon. aaba&#39; belongs to the VTA_C inflection class,
              ! so we continue to the VTA_C suffix boundary lexicon.
              LEXICON VTA_Stems
              aaba&#39;:aaba&#39;w VTA_Class=VTA_C_Boundary ;

              ! Suffix boundary
              LEXICON VTA_Class=VTA_C_Boundary
              0:%&gt;%&gt; VTA_Class=VTA_C_Flags ;

              ! This sublexicon makes sure that we get the correct 
              ! combination of person prefix (&#34;ni-&#34; in this case) and ending.
              ! The combinatorics is handled by matching the value of the 
              ! feature Prefix (NI in this case).
              LEXICON VTA_Class=VTA_C_Flags
              @R.Prefix.NI@ VTA_Class=VTA_C_Flags_Prefix=NI ;

              ! We need to match the correct order here
              LEXICON VTA_Class=VTA_C_Flags_Prefix=NI ;
              @U.Order.Ind@ VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings ;

              ! This lexicon enumerates endings for the inflection class
              ! VAT_C which correspond to person prefix &#34;ni-&#34; and order Ind.
              LEXICON VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings
              +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;
           ```

           For inflected forms of irregular lexemes, our paths become
           very simple. We just enumerate the entire form as one
           chunk without morpheme boundaries. This effectively prevents any
           phonological rules from applying, which is exactly what we want
           for irregular lexemes:

           ```
              LEXICON ROOT
              VTA_Irregular ;

              LEXICON VTA_Irregular
              izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;
           ```
        &#34;&#34;&#34;
        paths = []
        paradigm = self.paradigm
        klass = self.klass
        for surface, parts in self.forms:
            if self.regular:
                # Flag diacritics which:
                # (1) control combinations of person prefix and inflectional ending,
                # (2) check that we&#39;ve got the correct paradigm (this is needed to
                #     make sure that return to the correct paradigm after adding
                #     preverbs), and
                # (3) check the order (we track this because subordinate preverbs
                #     and the changed-conjunct marker require conjunct order and some
                #     preverbs have distinct independent and conjunct order surface
                #     forms) 
                set_prefix_flag, check_prefix_flag = LexcPath.get_prefix_flags(parts.prefix)
                _, check_paradigm_flag = LexcPath.get_paradigm_flags(paradigm)
                order, check_order_flag = self.get_order_flag()

                # The person prefix for this form
                prefix = &#34;NONE&#34; if parts.prefix == &#34;&#34; else parts.prefix.upper()

                # Continuation lexicons needed on this path
                person_prefix_lexicon = f&#34;{paradigm}_Prefix&#34;
                morpheme_boundary_lexicon = f&#34;{paradigm}_PrefixBoundary&#34;
                preverb_lexicon = (self.conf[&#34;prefix_root&#34;] # This can also be the prenoun lexicon depending on paradigm
                                   if &#34;prefix_root&#34; in self.conf
                                   else None)
                pos_stem_lexicon = f&#34;{self.conf[&#39;pos&#39;]}Stems&#34; # E.g. VerbStems
                paradigm_stem_lexicon = f&#34;{paradigm}_Stems&#34; # E.g. VTA_Stems
                inflection_class_lexicon = f&#34;{paradigm}_Class={klass}_Boundary&#34;
                check_prefix_lexicon = f&#34;{paradigm}_Class={klass}_Flags&#34;
                check_order_lexicon = f&#34;{paradigm}_Class={klass}_Flags_Prefix={prefix}&#34;
                ending_lexicon = f&#34;{paradigm}_Class={klass}_Prefix={prefix}_Order={order}_Endings&#34;
                
                path = [
                    LexcEntry(person_prefix_lexicon,
                              set_prefix_flag,
                              set_prefix_flag+parts.prefix,
                              morpheme_boundary_lexicon),
                    LexcEntry(morpheme_boundary_lexicon,
                              &#34;0&#34;,
                              escape(PREFIX_BOUNDARY),
                              preverb_lexicon or pos_stem_lexicon),
                    LexcEntry(pos_stem_lexicon,
                              check_paradigm_flag,
                              check_paradigm_flag,
                              paradigm_stem_lexicon),
                    LexcEntry(paradigm_stem_lexicon,
                              self.lemma,
                              self.stem,
                              inflection_class_lexicon),
                    LexcEntry(inflection_class_lexicon,
                              &#34;0&#34;,
                              escape(SUFFIX_BOUNDARY),
                              check_prefix_lexicon),
                    LexcEntry(check_prefix_lexicon,
                              check_prefix_flag,
                              check_prefix_flag,
                              check_order_lexicon),
                    LexcEntry(check_order_lexicon,
                              check_order_flag,
                              check_order_flag,
                              ending_lexicon),
                    LexcEntry(ending_lexicon,
                              &#34;&#34;.join(self.tags),
                              parts.suffix,
                              &#34;#&#34;)
                ]
                paths.append(path)
            else:
                # Irregular forms are treated as one chunk and simply enumerated.
                paths.append([LexcEntry(f&#34;{paradigm}_Irregular&#34;,
                                        f&#34;{self.lemma}{&#39;&#39;.join(self.tags)}&#34;,
                                        surface,
                                        &#34;#&#34;)])

        return paths

    def extend_lexicons(self, lexicons:dict) -&gt; None:
        &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
        def get_paradigm(s):
            return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
        for path in self.get_lexc_paths():
            paradigm = get_paradigm(path[0].lexicon)
            p_paradigm_flag, _ = LexcPath.get_paradigm_flags(paradigm)
            lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                      p_paradigm_flag,
                                                      p_paradigm_flag,
                                                      path[0].lexicon))
            for lexc_entry in path:
                if not lexc_entry.lexicon in lexicons:
                    lexicons[lexc_entry.lexicon] = set()
                lexicons[lexc_entry.lexicon].add(lexc_entry)
        
    def __str__(self):        
        paths = self.get_lexc_paths()
        res = &#34;&#34;
        for path in paths:
            for lexc_entry in path:
                res += f&#34;{lexc_entry}\n&#34;
            res += &#34;----\n&#34;
        return res

    def __hash__(self):
        return hash(str(self))</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.multichar_symbols"><code class="name">var <span class="ident">multichar_symbols</span> : set</code></dt>
<dd>
<div class="desc"><p>Multichar symbols (across all lexc files) are stored in this static
set</p></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.get_paradigm_flags"><code class="name flex">
<span>def <span class="ident">get_paradigm_flags</span></span>(<span>paradigm: str) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Get P and R flag diacritics for a given paradigm like VTA.</p>
<p>The flag diacritics will be added to <code>multichar_symbols</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def get_paradigm_flags(cls, paradigm:str) -&gt; tuple[str]:
    &#34;&#34;&#34;Get P and R flag diacritics for a given paradigm like VTA.

       The flag diacritics will be added to `multichar_symbols`.

    &#34;&#34;&#34;        
    pflag, rflag = f&#34;@P.Paradigm.{paradigm}@&#34;, f&#34;@R.Paradigm.{paradigm}@&#34;
    cls.multichar_symbols.update([pflag, rflag])        
    return pflag, rflag</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.get_prefix_flags"><code class="name flex">
<span>def <span class="ident">get_prefix_flags</span></span>(<span>prefix: str) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Get P and R flag diacritics like @P.Prefix.NI@ which
determine valid combinations of prefixes and suffixes.</p>
<p>The flag diacritics will be added to <code>multichar_symbols</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def get_prefix_flags(cls, prefix:str) -&gt; tuple[str]:
    &#34;&#34;&#34;Get P and R flag diacritics like @P.Prefix.NI@ which
       determine valid combinations of prefixes and suffixes.

       The flag diacritics will be added to `multichar_symbols`.

    &#34;&#34;&#34;
    prefix = &#34;NONE&#34; if prefix == &#34;&#34; else prefix.upper()
    pflag, rflag = f&#34;@P.Prefix.{prefix}@&#34;, f&#34;@R.Prefix.{prefix}@&#34;
    cls.multichar_symbols.update([pflag, rflag])
    return pflag, rflag</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.update_multichar_symbol_set"><code class="name flex">
<span>def <span class="ident">update_multichar_symbol_set</span></span>(<span>conf: dict) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>This function adds all multicharacter symbols speficied in a
configuration file + morpheme boundaries into the
<code>multichar_symbols</code> set.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
    &#34;&#34;&#34;This function adds all multicharacter symbols speficied in a
       configuration file + morpheme boundaries into the
       `multichar_symbols` set.

    &#34;&#34;&#34;
    cls.multichar_symbols.update(map(escape,conf[&#34;multichar_symbols&#34;]))
    cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
    cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.extend_lexicons"><code class="name flex">
<span>def <span class="ident">extend_lexicons</span></span>(<span>self, lexicons: dict) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Add the lexc paths representing this path to lexicons.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extend_lexicons(self, lexicons:dict) -&gt; None:
    &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
    def get_paradigm(s):
        return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
    for path in self.get_lexc_paths():
        paradigm = get_paradigm(path[0].lexicon)
        p_paradigm_flag, _ = LexcPath.get_paradigm_flags(paradigm)
        lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                  p_paradigm_flag,
                                                  p_paradigm_flag,
                                                  path[0].lexicon))
        for lexc_entry in path:
            if not lexc_entry.lexicon in lexicons:
                lexicons[lexc_entry.lexicon] = set()
            lexicons[lexc_entry.lexicon].add(lexc_entry)</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.get_lexc_paths"><code class="name flex">
<span>def <span class="ident">get_lexc_paths</span></span>(<span>self) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Convert this path into a list of lexc lexicon paths starting
at a person prefix lexicon (this could be VTA_Prefix, NA_Prefix,
etc.) and ending in the terminal lexicon #. Each path is a
sequence of lexc sublexicon entries.</p>
<p>There will be one list-element for each surface form (note that
there may be several surface forms Form1Surface, Form2Surface,
&hellip;).</p>
<p>For inflected forms of regular lexemes, our paths will look
like this (here, for the example analysis and form
aaba'+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba'wigosiinaadogenan):</p>
<pre><code>   ! Person prefix lexicon for nouns and verbs. For all other 
   ! word classes the prefix is always empty (@P.Prefix.NONE@)
   LEXICON VTA_Prefix
   @P.Prefix.NI@:@P.Prefix.NI@ni VTA_PrefixBoundary ;

   ! Morpheme boundary for person prefix. Note that we can jump
   ! to a preverb lexicon here. For all word classes apart from
   ! nouns and verbs, we jump directly to the a stem lexicon.
   LEXICON VTA_PrefixBoundary
   0:%&lt;%&lt; PreverbRoot ;

   ! After adding preverbs, we return to this lexicon. Need to
   ! match the correct paradigm here
   LEXICON VerbStems
   @R.Paradigm.VTA@ VTA_Stems ;

   ! Stem lexicon. aaba' belongs to the VTA_C inflection class,
   ! so we continue to the VTA_C suffix boundary lexicon.
   LEXICON VTA_Stems
   aaba':aaba'w VTA_Class=VTA_C_Boundary ;

   ! Suffix boundary
   LEXICON VTA_Class=VTA_C_Boundary
   0:%&gt;%&gt; VTA_Class=VTA_C_Flags ;

   ! This sublexicon makes sure that we get the correct 
   ! combination of person prefix (&quot;ni-&quot; in this case) and ending.
   ! The combinatorics is handled by matching the value of the 
   ! feature Prefix (NI in this case).
   LEXICON VTA_Class=VTA_C_Flags
   @R.Prefix.NI@ VTA_Class=VTA_C_Flags_Prefix=NI ;

   ! We need to match the correct order here
   LEXICON VTA_Class=VTA_C_Flags_Prefix=NI ;
   @U.Order.Ind@ VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings ;

   ! This lexicon enumerates endings for the inflection class
   ! VAT_C which correspond to person prefix &quot;ni-&quot; and order Ind.
   LEXICON VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings
   +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;
</code></pre>
<p>For inflected forms of irregular lexemes, our paths become
very simple. We just enumerate the entire form as one
chunk without morpheme boundaries. This effectively prevents any
phonological rules from applying, which is exactly what we want
for irregular lexemes:</p>
<pre><code>   LEXICON ROOT
   VTA_Irregular ;

   LEXICON VTA_Irregular
   izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_lexc_paths(self) -&gt; list[list[LexcEntry]]:
    &#34;&#34;&#34;Convert this path into a list of lexc lexicon paths starting
       at a person prefix lexicon (this could be VTA_Prefix, NA_Prefix, 
       etc.) and ending in the terminal lexicon #. Each path is a 
       sequence of lexc sublexicon entries.

       There will be one list-element for each surface form (note that 
       there may be several surface forms Form1Surface, Form2Surface, 
       ...).

       For inflected forms of regular lexemes, our paths will look
       like this (here, for the example analysis and form
       aaba&#39;+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba&#39;wigosiinaadogenan):

       ```
          ! Person prefix lexicon for nouns and verbs. For all other 
          ! word classes the prefix is always empty (@P.Prefix.NONE@)
          LEXICON VTA_Prefix
          @P.Prefix.NI@:@P.Prefix.NI@ni VTA_PrefixBoundary ;

          ! Morpheme boundary for person prefix. Note that we can jump
          ! to a preverb lexicon here. For all word classes apart from
          ! nouns and verbs, we jump directly to the a stem lexicon.
          LEXICON VTA_PrefixBoundary
          0:%&lt;%&lt; PreverbRoot ;
    
          ! After adding preverbs, we return to this lexicon. Need to
          ! match the correct paradigm here
          LEXICON VerbStems
          @R.Paradigm.VTA@ VTA_Stems ;

          ! Stem lexicon. aaba&#39; belongs to the VTA_C inflection class,
          ! so we continue to the VTA_C suffix boundary lexicon.
          LEXICON VTA_Stems
          aaba&#39;:aaba&#39;w VTA_Class=VTA_C_Boundary ;

          ! Suffix boundary
          LEXICON VTA_Class=VTA_C_Boundary
          0:%&gt;%&gt; VTA_Class=VTA_C_Flags ;

          ! This sublexicon makes sure that we get the correct 
          ! combination of person prefix (&#34;ni-&#34; in this case) and ending.
          ! The combinatorics is handled by matching the value of the 
          ! feature Prefix (NI in this case).
          LEXICON VTA_Class=VTA_C_Flags
          @R.Prefix.NI@ VTA_Class=VTA_C_Flags_Prefix=NI ;

          ! We need to match the correct order here
          LEXICON VTA_Class=VTA_C_Flags_Prefix=NI ;
          @U.Order.Ind@ VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings ;

          ! This lexicon enumerates endings for the inflection class
          ! VAT_C which correspond to person prefix &#34;ni-&#34; and order Ind.
          LEXICON VTA_Class=VTA_C_Prefix=NI_Order=Ind_Endings
          +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;
       ```

       For inflected forms of irregular lexemes, our paths become
       very simple. We just enumerate the entire form as one
       chunk without morpheme boundaries. This effectively prevents any
       phonological rules from applying, which is exactly what we want
       for irregular lexemes:

       ```
          LEXICON ROOT
          VTA_Irregular ;

          LEXICON VTA_Irregular
          izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;
       ```
    &#34;&#34;&#34;
    paths = []
    paradigm = self.paradigm
    klass = self.klass
    for surface, parts in self.forms:
        if self.regular:
            # Flag diacritics which:
            # (1) control combinations of person prefix and inflectional ending,
            # (2) check that we&#39;ve got the correct paradigm (this is needed to
            #     make sure that return to the correct paradigm after adding
            #     preverbs), and
            # (3) check the order (we track this because subordinate preverbs
            #     and the changed-conjunct marker require conjunct order and some
            #     preverbs have distinct independent and conjunct order surface
            #     forms) 
            set_prefix_flag, check_prefix_flag = LexcPath.get_prefix_flags(parts.prefix)
            _, check_paradigm_flag = LexcPath.get_paradigm_flags(paradigm)
            order, check_order_flag = self.get_order_flag()

            # The person prefix for this form
            prefix = &#34;NONE&#34; if parts.prefix == &#34;&#34; else parts.prefix.upper()

            # Continuation lexicons needed on this path
            person_prefix_lexicon = f&#34;{paradigm}_Prefix&#34;
            morpheme_boundary_lexicon = f&#34;{paradigm}_PrefixBoundary&#34;
            preverb_lexicon = (self.conf[&#34;prefix_root&#34;] # This can also be the prenoun lexicon depending on paradigm
                               if &#34;prefix_root&#34; in self.conf
                               else None)
            pos_stem_lexicon = f&#34;{self.conf[&#39;pos&#39;]}Stems&#34; # E.g. VerbStems
            paradigm_stem_lexicon = f&#34;{paradigm}_Stems&#34; # E.g. VTA_Stems
            inflection_class_lexicon = f&#34;{paradigm}_Class={klass}_Boundary&#34;
            check_prefix_lexicon = f&#34;{paradigm}_Class={klass}_Flags&#34;
            check_order_lexicon = f&#34;{paradigm}_Class={klass}_Flags_Prefix={prefix}&#34;
            ending_lexicon = f&#34;{paradigm}_Class={klass}_Prefix={prefix}_Order={order}_Endings&#34;
            
            path = [
                LexcEntry(person_prefix_lexicon,
                          set_prefix_flag,
                          set_prefix_flag+parts.prefix,
                          morpheme_boundary_lexicon),
                LexcEntry(morpheme_boundary_lexicon,
                          &#34;0&#34;,
                          escape(PREFIX_BOUNDARY),
                          preverb_lexicon or pos_stem_lexicon),
                LexcEntry(pos_stem_lexicon,
                          check_paradigm_flag,
                          check_paradigm_flag,
                          paradigm_stem_lexicon),
                LexcEntry(paradigm_stem_lexicon,
                          self.lemma,
                          self.stem,
                          inflection_class_lexicon),
                LexcEntry(inflection_class_lexicon,
                          &#34;0&#34;,
                          escape(SUFFIX_BOUNDARY),
                          check_prefix_lexicon),
                LexcEntry(check_prefix_lexicon,
                          check_prefix_flag,
                          check_prefix_flag,
                          check_order_lexicon),
                LexcEntry(check_order_lexicon,
                          check_order_flag,
                          check_order_flag,
                          ending_lexicon),
                LexcEntry(ending_lexicon,
                          &#34;&#34;.join(self.tags),
                          parts.suffix,
                          &#34;#&#34;)
            ]
            paths.append(path)
        else:
            # Irregular forms are treated as one chunk and simply enumerated.
            paths.append([LexcEntry(f&#34;{paradigm}_Irregular&#34;,
                                    f&#34;{self.lemma}{&#39;&#39;.join(self.tags)}&#34;,
                                    surface,
                                    &#34;#&#34;)])

    return paths</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.get_order_flag"><code class="name flex">
<span>def <span class="ident">get_order_flag</span></span>(<span>self) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Get a U flag matching the order of this LexcPath: Ind, Cnj or
Other (in case of imperative or other unspecified order).</p>
<p>The flag diacritic will be added to <code>multichar_symbols</code>.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_order_flag(self) -&gt; tuple[str]:
    &#34;&#34;&#34;Get a U flag matching the order of this LexcPath: Ind, Cnj or
       Other (in case of imperative or other unspecified order).

       The flag diacritic will be added to `multichar_symbols`.
    &#34;&#34;&#34;
    order = &#34;Other&#34;
    if &#34;+Ind&#34; in self.tags:
        order = &#34;Ind&#34;
    elif &#34;+Cnj&#34; in self.tags:
        order = &#34;Cnj&#34;
    flag = f&#34;@U.Order.{order}@&#34;
    LexcPath.multichar_symbols.update([flag])
    return order, flag</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.harvest_multichar_symbols"><code class="name flex">
<span>def <span class="ident">harvest_multichar_symbols</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Add all morphological features like "+VTA", "+Ind" and "+1SgSubj"
from this path to the multichar_symbols set</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def harvest_multichar_symbols(self) -&gt; None:
    &#34;&#34;&#34;Add all morphological features like &#34;+VTA&#34;, &#34;+Ind&#34; and &#34;+1SgSubj&#34;
       from this path to the multichar_symbols set

    &#34;&#34;&#34;
    for tag in self.tags:
        LexcPath.multichar_symbols.add(tag)</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.read_forms"><code class="name flex">
<span>def <span class="ident">read_forms</span></span>(<span>self, row: pandas.core.series.Series, conf: dict) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Read all forms on the given dataframe row. Store both the plain
surface form and segmented form.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_forms(self, row:pd.core.series.Series, conf:dict) -&gt; None:
    &#34;&#34;&#34;Read all forms on the given dataframe row. Store both the plain
       surface form and segmented form.

    &#34;&#34;&#34;
    def get_form_indices() -&gt; list[int]:
        # Return all indices i which are associated with a surface
        # form on this row, i.e. i where Form{i}Surface is a
        # column on the row and the form in that column is
        # non-empty.
        missing = conf[&#34;missing_form_marker&#34;]
        return [i for i in range(MAXFORMS) if f&#34;Form{i}Surface&#34; in row and
                                              not row[f&#34;Form{i}Surface&#34;] in [missing, &#34;&#34;]]
    
    self.forms = [(row[f&#34;Form{i}Surface&#34;], split_form(row[f&#34;Form{i}Split&#34;]))
                  for i in get_form_indices()]
    if len(self.forms) == 0:
        raise ValueError(f&#34;No surface forms given for row: {row.to_dict()}&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="csv2fst.lexc_path.SplitForm"><code class="flex name class">
<span>class <span class="ident">SplitForm</span></span>
<span>(</span><span>prefix, stem, suffix)</span>
</code></dt>
<dd>
<div class="desc"><p>SplitForm represents an inflected word form consisting of a
prefix, stem and suffix:</p>
<pre><code>&quot;pre&lt;&lt;st&gt;&gt;suf&quot;
</code></pre>
<p>corresponds to:</p>
<pre><code>split_form = SplitForm(&quot;pre&quot;,&quot;st&quot;,&quot;suf&quot;)
</code></pre>
<p>Access features as:</p>
<pre><code>split_form.prefix, split_form.stem, split_form.suffix
</code></pre></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="csv2fst.lexc_path.SplitForm.prefix"><code class="name">var <span class="ident">prefix</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="csv2fst.lexc_path.SplitForm.stem"><code class="name">var <span class="ident">stem</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="csv2fst.lexc_path.SplitForm.suffix"><code class="name">var <span class="ident">suffix</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="csv2fst" href="index.html">csv2fst</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="csv2fst.lexc_path.MAXFORMS" href="#csv2fst.lexc_path.MAXFORMS">MAXFORMS</a></code></li>
<li><code><a title="csv2fst.lexc_path.PREFIX_BOUNDARY" href="#csv2fst.lexc_path.PREFIX_BOUNDARY">PREFIX_BOUNDARY</a></code></li>
<li><code><a title="csv2fst.lexc_path.SUFFIX_BOUNDARY" href="#csv2fst.lexc_path.SUFFIX_BOUNDARY">SUFFIX_BOUNDARY</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="csv2fst.lexc_path.entry2str" href="#csv2fst.lexc_path.entry2str">entry2str</a></code></li>
<li><code><a title="csv2fst.lexc_path.escape" href="#csv2fst.lexc_path.escape">escape</a></code></li>
<li><code><a title="csv2fst.lexc_path.split_form" href="#csv2fst.lexc_path.split_form">split_form</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="csv2fst.lexc_path.LexcEntry" href="#csv2fst.lexc_path.LexcEntry">LexcEntry</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.LexcEntry.analysis" href="#csv2fst.lexc_path.LexcEntry.analysis">analysis</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.lexicon" href="#csv2fst.lexc_path.LexcEntry.lexicon">lexicon</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.next_lexicon" href="#csv2fst.lexc_path.LexcEntry.next_lexicon">next_lexicon</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.surface" href="#csv2fst.lexc_path.LexcEntry.surface">surface</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="csv2fst.lexc_path.LexcPath" href="#csv2fst.lexc_path.LexcPath">LexcPath</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.LexcPath.extend_lexicons" href="#csv2fst.lexc_path.LexcPath.extend_lexicons">extend_lexicons</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.get_lexc_paths" href="#csv2fst.lexc_path.LexcPath.get_lexc_paths">get_lexc_paths</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.get_order_flag" href="#csv2fst.lexc_path.LexcPath.get_order_flag">get_order_flag</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.get_paradigm_flags" href="#csv2fst.lexc_path.LexcPath.get_paradigm_flags">get_paradigm_flags</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.get_prefix_flags" href="#csv2fst.lexc_path.LexcPath.get_prefix_flags">get_prefix_flags</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.harvest_multichar_symbols" href="#csv2fst.lexc_path.LexcPath.harvest_multichar_symbols">harvest_multichar_symbols</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.multichar_symbols" href="#csv2fst.lexc_path.LexcPath.multichar_symbols">multichar_symbols</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.read_forms" href="#csv2fst.lexc_path.LexcPath.read_forms">read_forms</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.update_multichar_symbol_set" href="#csv2fst.lexc_path.LexcPath.update_multichar_symbol_set">update_multichar_symbol_set</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="csv2fst.lexc_path.SplitForm" href="#csv2fst.lexc_path.SplitForm">SplitForm</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.SplitForm.prefix" href="#csv2fst.lexc_path.SplitForm.prefix">prefix</a></code></li>
<li><code><a title="csv2fst.lexc_path.SplitForm.stem" href="#csv2fst.lexc_path.SplitForm.stem">stem</a></code></li>
<li><code><a title="csv2fst.lexc_path.SplitForm.suffix" href="#csv2fst.lexc_path.SplitForm.suffix">suffix</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>