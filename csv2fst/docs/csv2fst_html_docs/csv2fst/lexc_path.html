<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>csv2fst.lexc_path API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>csv2fst.lexc_path</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from sys import stderr
import re
import pandas as pd
from collections import namedtuple
from log import warn

# Maximum number of alternate forms for a single analysis in the
# spreadsheets
MAXFORMS=100

PREFIX_BOUNDARY = &#34;&lt;&lt;&#34;
SUFFIX_BOUNDARY = &#34;&gt;&gt;&#34;

# LexcEntry represents a lexc sublexicon entry 
LexcEntry = namedtuple(&#34;LexcEntry&#34;,
                       [&#34;lexicon&#34;,
                        &#34;analysis&#34;,
                        &#34;surface&#34;,
                        &#34;next_lexicon&#34;])

# SplitForm represents a form consisting of a prefix, stem and suffix
SplitForm = namedtuple(&#34;SplitForm&#34;,
                       [&#34;prefix&#34;,
                        &#34;stem&#34;,
                        &#34;suffix&#34;])

def entry2str(entry:LexcEntry) -&gt; str:
    &#34;&#34;&#34; Return the string representation of a lexc lexicon entry &#34;&#34;&#34;
    if entry.analysis == entry.surface:
        if entry.analysis == &#34;0&#34;:
            return f&#34;{entry.next_lexicon} ;&#34;
        else:
            return f&#34;{entry.analysis} {entry.next_lexicon} ;&#34;
    else:
        return f&#34;{entry.analysis}:{entry.surface} {entry.next_lexicon} ;&#34;

def escape(symbol:str) -&gt; str:
    &#34;&#34;&#34; Escape lexc special characters using a %-sign &#34;&#34;&#34;
    return re.sub(&#34;(?&lt;!%)([!%&lt;&gt;0/#; ])&#34;,r&#34;%\1&#34;,symbol)

def split_form(form:str) -&gt; SplitForm:
    &#34;&#34;&#34;Split a form prefix&lt;&lt;stem&gt;&gt;suffix at boundaries.&#34;&#34;&#34;
    # re.split results in a 5-element array [prefix, &#34;&lt;&lt;&#34;, stem, &#34;&gt;&gt;&#34;,
    # suffix]
    if not &#34;&lt;&lt;&#34; in form:
        form = &#34;&lt;&lt;&#34; + form
        warn(&#34;Invalid form: {form}. Appending morpheme boundary &#39;&lt;&lt;&#39; at the start.&#34;)    
    if not &#34;&gt;&gt;&#34; in form:
        form += &#34;&gt;&gt;&#34;
        warn(&#34;Invalid form: {form}. Aappending morpheme boundary &#39;&gt;&gt;&#39; at the end.&#34;)
    form = re.split(f&#34;({PREFIX_BOUNDARY}|{SUFFIX_BOUNDARY})&#34;, form)
    if len(form) != 5:
        raise ValueError(f&#34;Invalid form: {orig_form}. Split: {form}&#34;)
    return SplitForm(escape(form[0]), escape(form[2]), escape(form[4]))


class LexcPath:
    # All multichar symbols (across the entire lexc file) are stored
    # in this static set
    multichar_symbols:set[str] = set()
    pre_element_tag:str = None
    
    @classmethod
    def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
        &#34;&#34;&#34;Must be called when the first LexcPath object is
           initialized.&#34;&#34;&#34;
        cls.multichar_symbols.update(set(map(escape,conf[&#34;multichar_symbols&#34;])))
        #cls.pre_element_tag = escape(conf[&#34;pre_element_tag&#34;])
        cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
        cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))
        #cls.multichar_symbols.add(cls.pre_element_tag)
        
    @classmethod
    def __get_prefix_flags(cls, prefix:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get the P and R flags like @P.Prefi.=NI@ which determine valid
           combinations of prefixes and suffixes.

            The flag diacritics will be added to multichar symbols.
        &#34;&#34;&#34;
        prefix = &#34;NONE&#34; if prefix == &#34;&#34; else prefix.upper()
        pflag, rflag = f&#34;@P.Prefix.{prefix}@&#34;, f&#34;@R.Prefix.{prefix}@&#34;
        cls.multichar_symbols.update([pflag, rflag])
        return pflag, rflag

    @classmethod
    def __get_paradigm_flags(cls, paradigm:str) -&gt; tuple[str]:
        pflag, rflag = f&#34;@P.Paradigm.{paradigm}@&#34;, f&#34;@R.Paradigm.{paradigm}@&#34;
        cls.multichar_symbols.update([pflag, rflag])        
        return pflag, rflag
    
    def __get_order_flag(self) -&gt; tuple[str]:
        order = &#34;Other&#34;
        if &#34;+Ind&#34; in self.tags:
            order = &#34;Ind&#34;
        elif &#34;+Cnj&#34; in self.tags:
            order = &#34;Cnj&#34;
        flag = f&#34;@U.Order.{order}@&#34;
        LexcPath.multichar_symbols.update([flag])
        return order, flag

    def __init__(self, row, conf, regular:bool):
        self.root_lexicon = conf[&#34;root_lexicon&#34;]
        self.row = row
        self.conf = conf
        self.regular = regular
        self.paradigm = row[&#34;Paradigm&#34;]
        self.klass = row[&#34;Class&#34;]
        self.lemma = escape(row[&#34;Lemma&#34;])
        self.stem = escape(row[&#34;Stem&#34;])
        self.tags = [escape(f&#34;+{row[feat]}&#34;)
                     for feat in conf[&#34;morph_features&#34;]
                     if (row[feat] != conf[&#34;missing_tag_marker&#34;] and
                         row[feat] != &#34;&#34;)]
#        if LexcPath.multichar_symbols == None:
#        LexcPath.__upda_multichar_symbol_set(conf)
        self.__harvest_multichar_symbols()

        try:
            self.__read_forms(row, conf)
        except ValueError as e:
            warn(e)
            
    def __harvest_multichar_symbols(self) -&gt; None:
        &#34;&#34;&#34;Add all multichar symbols from this entry to the multichar symbol
           set
        &#34;&#34;&#34;
        for tag in self.tags:
            LexcPath.multichar_symbols.add(tag)

    def __read_forms(self, row:pd.core.series.Series, conf:dict) -&gt; None:
        &#34;&#34;&#34;Read all forms on the given dataframe row.&#34;&#34;&#34;
        self.forms = [(row[f&#34;Form{i}Surface&#34;], split_form(row[f&#34;Form{i}Split&#34;]))
                      for i in range(MAXFORMS)
                      if (f&#34;Form{i}Surface&#34; in row and
                          row[f&#34;Form{i}Surface&#34;] != conf[&#34;missing_form_marker&#34;] and
                          row[f&#34;Form{i}Surface&#34;] != &#34;&#34;)]
        if len(self.forms) == 0:
            raise ValueError(f&#34;No surface forms given for row: {row.to_dict()}&#34;)
        
    def __get_lexc_paths(self) -&gt; list[list[LexcEntry]]:
        &#34;&#34;&#34;Convert this path entry into a list of lexc lexicon paths starting
           at the ROOT lexicon (this could be VerbRoot, NounRoot etc.)
           and ending in #. Each path is a sequence of lexc sublexicon
           entries.

           There will be one path for each surface form.

           For inflected forms of regular lexemes, our paths will look
           like this (here, for the example analysis and form
           aaba&#39;+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba&#39;wigosiinaadogenan):

              LEXICON ROOT
              VTA:Prefix ;

              LEXICON VTA:Prefix
              @P.Prefix.NI@:@P.Prefix.NI@ni VTA:PrefixBoundary ;

              LEXICON VTA:PrefixBoundary
              0:%&lt;%&lt; VTA:PreElement ;

              LEXICON VTA:PreElement
              [PREVERB] VTA:Stems ;

              LEXICON VTA:Stems
              aaba&#39;:aaba&#39;w VTA:Class=VTA_C:Boundary ;

              LEXICON VTA:Class=VTA_C:Boundary
              0:%&gt;%&gt; VTA:Class=VTA_C:Flags ;

              LEXICON VTA:Class=VTA_C:Flags
              @R.Prefix.NI@ VTA:Class=VTA_C:Prefix=NI:Endings ;

              LEXICON VTA:Class=VTA_C:Prefix=NI:Endings
              +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;

           For inflected forms of irregular lexemes, our pahts become
           very simple. We just enumerate the entire form as one
           chunk:

              LEXICON ROOT
              VTA:Irregular ;

              LEXICON VTA:Irregular
              izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;

        &#34;&#34;&#34;
        paths = []
        paradigm = self.paradigm
        klass = self.klass
        pre_tag = LexcPath.pre_element_tag
        for surface, parts in self.forms:
            if self.regular:
                p_prefix_flag, r_prefix_flag = LexcPath.__get_prefix_flags(parts.prefix)
                _, r_paradigm_flag = LexcPath.__get_paradigm_flags(paradigm)
                order, r_order_flag = self.__get_order_flag()
                prefix_id = &#34;NONE&#34; if parts.prefix == &#34;&#34; else parts.prefix.upper()
                # The following lexc sublexicon entries generate this form. 
                path = [
                    # @P.Prefix.&lt;X&gt;@_@P.Prefix.&lt;X&gt;@&lt;x&gt; &lt;Paradigm&gt;_PrefixBoundary ;
                    LexcEntry(f&#34;{paradigm}_Prefix&#34;,
                              p_prefix_flag,
                              p_prefix_flag+parts.prefix,
                              f&#34;{paradigm}_PrefixBoundary&#34;),
                    # 0_%&lt;%&lt; &lt;Paradigm&gt;_PreElement ;
                    LexcEntry(f&#34;{paradigm}_PrefixBoundary&#34;,
                              &#34;0&#34;,
                              escape(PREFIX_BOUNDARY),
                              self.conf[&#34;prefix_root&#34;]
                              if &#34;prefix_root&#34; in self.conf
                              else f&#34;{self.conf[&#39;pos&#39;]}Stems&#34;),
#                              f&#34;{paradigm}_PreElement&#34;),
                    # &lt;PreElement&gt; &lt;Paradigm&gt;_Stems ;
                    LexcEntry(f&#34;{self.conf[&#39;pos&#39;]}Stems&#34;,
                              r_paradigm_flag,
                              r_paradigm_flag,
                              f&#34;{paradigm}_Stems&#34;),
                    # &lt;lemma&gt;_&lt;stem&gt; &lt;Paradigm&gt;_Class=&lt;class&gt;_Boundary ;
                    LexcEntry(f&#34;{paradigm}_Stems&#34;,
                              self.lemma,
                              self.stem,
                              f&#34;{paradigm}_Class={klass}_Boundary&#34;),
                    # 0_%&gt;%&gt; &lt;Paradigm&gt;_Class=&lt;class&gt;_Flags ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Boundary&#34;,
                              &#34;0&#34;,
                              escape(SUFFIX_BOUNDARY),
                              f&#34;{paradigm}_Class={klass}_Flags&#34;),
                    # @R.Prefix.&lt;X&gt;@ &lt;Paradigm&gt;_Class=&lt;class&gt;_Prefix=&lt;X&gt;_Endings ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Flags&#34;,
                              r_prefix_flag,
                              r_prefix_flag,
                              f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}&#34;),
                    # @U.Order.&lt;Y&gt;@ &lt;Paradigm&gt;_Class=&lt;class&gt;_Prefix=&lt;X&gt;_Order=&lt;Y&gt;_Endings
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}&#34;,
                              r_order_flag,
                              r_order_flag,
                              f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}_Endings&#34;),
                    # &lt;tags&gt;_&lt;ending&gt; # ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}_Endings&#34;,
                              &#34;&#34;.join(self.tags),
                              parts.suffix,
                              &#34;#&#34;)
                ]
                paths.append(path)
            else:
                # Irregular forms are treated as one chunk and simply enumerated.
                paths.append([LexcEntry(f&#34;{paradigm}_Irregular&#34;,
                                        f&#34;{self.lemma}{&#39;&#39;.join(self.tags)}&#34;,
                                        surface,
                                        &#34;#&#34;)])

        return paths

    def extend_lexicons(self, lexicons:dict) -&gt; None:
        &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
        def get_paradigm(s):
            return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
        for path in self.__get_lexc_paths():
            paradigm = get_paradigm(path[0].lexicon)
            p_paradigm_flag, _ = LexcPath.__get_paradigm_flags(paradigm)
            lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                      p_paradigm_flag,
                                                      p_paradigm_flag,
                                                      path[0].lexicon))
            for lexc_entry in path:
                if not lexc_entry.lexicon in lexicons:
                    lexicons[lexc_entry.lexicon] = set()
                lexicons[lexc_entry.lexicon].add(lexc_entry)
        
    def __str__(self):        
        paths = self.get_lexc_paths()
        res = &#34;&#34;
        for path in paths:
            for lexc_entry in path:
                res += f&#34;{lexc_entry}\n&#34;
            res += &#34;----\n&#34;
        return res

    def __hash__(self):
        return hash(str(self))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="csv2fst.lexc_path.entry2str"><code class="name flex">
<span>def <span class="ident">entry2str</span></span>(<span>entry: <a title="csv2fst.lexc_path.LexcEntry" href="#csv2fst.lexc_path.LexcEntry">LexcEntry</a>) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Return the string representation of a lexc lexicon entry</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def entry2str(entry:LexcEntry) -&gt; str:
    &#34;&#34;&#34; Return the string representation of a lexc lexicon entry &#34;&#34;&#34;
    if entry.analysis == entry.surface:
        if entry.analysis == &#34;0&#34;:
            return f&#34;{entry.next_lexicon} ;&#34;
        else:
            return f&#34;{entry.analysis} {entry.next_lexicon} ;&#34;
    else:
        return f&#34;{entry.analysis}:{entry.surface} {entry.next_lexicon} ;&#34;</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.escape"><code class="name flex">
<span>def <span class="ident">escape</span></span>(<span>symbol: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Escape lexc special characters using a %-sign</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def escape(symbol:str) -&gt; str:
    &#34;&#34;&#34; Escape lexc special characters using a %-sign &#34;&#34;&#34;
    return re.sub(&#34;(?&lt;!%)([!%&lt;&gt;0/#; ])&#34;,r&#34;%\1&#34;,symbol)</code></pre>
</details>
</dd>
<dt id="csv2fst.lexc_path.split_form"><code class="name flex">
<span>def <span class="ident">split_form</span></span>(<span>form: str) ‑> <a title="csv2fst.lexc_path.SplitForm" href="#csv2fst.lexc_path.SplitForm">SplitForm</a></span>
</code></dt>
<dd>
<div class="desc"><p>Split a form prefix&lt;<stem>&gt;suffix at boundaries.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_form(form:str) -&gt; SplitForm:
    &#34;&#34;&#34;Split a form prefix&lt;&lt;stem&gt;&gt;suffix at boundaries.&#34;&#34;&#34;
    # re.split results in a 5-element array [prefix, &#34;&lt;&lt;&#34;, stem, &#34;&gt;&gt;&#34;,
    # suffix]
    if not &#34;&lt;&lt;&#34; in form:
        form = &#34;&lt;&lt;&#34; + form
        warn(&#34;Invalid form: {form}. Appending morpheme boundary &#39;&lt;&lt;&#39; at the start.&#34;)    
    if not &#34;&gt;&gt;&#34; in form:
        form += &#34;&gt;&gt;&#34;
        warn(&#34;Invalid form: {form}. Aappending morpheme boundary &#39;&gt;&gt;&#39; at the end.&#34;)
    form = re.split(f&#34;({PREFIX_BOUNDARY}|{SUFFIX_BOUNDARY})&#34;, form)
    if len(form) != 5:
        raise ValueError(f&#34;Invalid form: {orig_form}. Split: {form}&#34;)
    return SplitForm(escape(form[0]), escape(form[2]), escape(form[4]))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="csv2fst.lexc_path.LexcEntry"><code class="flex name class">
<span>class <span class="ident">LexcEntry</span></span>
<span>(</span><span>lexicon, analysis, surface, next_lexicon)</span>
</code></dt>
<dd>
<div class="desc"><p>LexcEntry(lexicon, analysis, surface, next_lexicon)</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcEntry.analysis"><code class="name">var <span class="ident">analysis</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.lexicon"><code class="name">var <span class="ident">lexicon</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.next_lexicon"><code class="name">var <span class="ident">next_lexicon</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 3</p></div>
</dd>
<dt id="csv2fst.lexc_path.LexcEntry.surface"><code class="name">var <span class="ident">surface</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
</dl>
</dd>
<dt id="csv2fst.lexc_path.LexcPath"><code class="flex name class">
<span>class <span class="ident">LexcPath</span></span>
<span>(</span><span>row, conf, regular: bool)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LexcPath:
    # All multichar symbols (across the entire lexc file) are stored
    # in this static set
    multichar_symbols:set[str] = set()
    pre_element_tag:str = None
    
    @classmethod
    def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
        &#34;&#34;&#34;Must be called when the first LexcPath object is
           initialized.&#34;&#34;&#34;
        cls.multichar_symbols.update(set(map(escape,conf[&#34;multichar_symbols&#34;])))
        #cls.pre_element_tag = escape(conf[&#34;pre_element_tag&#34;])
        cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
        cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))
        #cls.multichar_symbols.add(cls.pre_element_tag)
        
    @classmethod
    def __get_prefix_flags(cls, prefix:str) -&gt; tuple[str]:
        &#34;&#34;&#34;Get the P and R flags like @P.Prefi.=NI@ which determine valid
           combinations of prefixes and suffixes.

            The flag diacritics will be added to multichar symbols.
        &#34;&#34;&#34;
        prefix = &#34;NONE&#34; if prefix == &#34;&#34; else prefix.upper()
        pflag, rflag = f&#34;@P.Prefix.{prefix}@&#34;, f&#34;@R.Prefix.{prefix}@&#34;
        cls.multichar_symbols.update([pflag, rflag])
        return pflag, rflag

    @classmethod
    def __get_paradigm_flags(cls, paradigm:str) -&gt; tuple[str]:
        pflag, rflag = f&#34;@P.Paradigm.{paradigm}@&#34;, f&#34;@R.Paradigm.{paradigm}@&#34;
        cls.multichar_symbols.update([pflag, rflag])        
        return pflag, rflag
    
    def __get_order_flag(self) -&gt; tuple[str]:
        order = &#34;Other&#34;
        if &#34;+Ind&#34; in self.tags:
            order = &#34;Ind&#34;
        elif &#34;+Cnj&#34; in self.tags:
            order = &#34;Cnj&#34;
        flag = f&#34;@U.Order.{order}@&#34;
        LexcPath.multichar_symbols.update([flag])
        return order, flag

    def __init__(self, row, conf, regular:bool):
        self.root_lexicon = conf[&#34;root_lexicon&#34;]
        self.row = row
        self.conf = conf
        self.regular = regular
        self.paradigm = row[&#34;Paradigm&#34;]
        self.klass = row[&#34;Class&#34;]
        self.lemma = escape(row[&#34;Lemma&#34;])
        self.stem = escape(row[&#34;Stem&#34;])
        self.tags = [escape(f&#34;+{row[feat]}&#34;)
                     for feat in conf[&#34;morph_features&#34;]
                     if (row[feat] != conf[&#34;missing_tag_marker&#34;] and
                         row[feat] != &#34;&#34;)]
#        if LexcPath.multichar_symbols == None:
#        LexcPath.__upda_multichar_symbol_set(conf)
        self.__harvest_multichar_symbols()

        try:
            self.__read_forms(row, conf)
        except ValueError as e:
            warn(e)
            
    def __harvest_multichar_symbols(self) -&gt; None:
        &#34;&#34;&#34;Add all multichar symbols from this entry to the multichar symbol
           set
        &#34;&#34;&#34;
        for tag in self.tags:
            LexcPath.multichar_symbols.add(tag)

    def __read_forms(self, row:pd.core.series.Series, conf:dict) -&gt; None:
        &#34;&#34;&#34;Read all forms on the given dataframe row.&#34;&#34;&#34;
        self.forms = [(row[f&#34;Form{i}Surface&#34;], split_form(row[f&#34;Form{i}Split&#34;]))
                      for i in range(MAXFORMS)
                      if (f&#34;Form{i}Surface&#34; in row and
                          row[f&#34;Form{i}Surface&#34;] != conf[&#34;missing_form_marker&#34;] and
                          row[f&#34;Form{i}Surface&#34;] != &#34;&#34;)]
        if len(self.forms) == 0:
            raise ValueError(f&#34;No surface forms given for row: {row.to_dict()}&#34;)
        
    def __get_lexc_paths(self) -&gt; list[list[LexcEntry]]:
        &#34;&#34;&#34;Convert this path entry into a list of lexc lexicon paths starting
           at the ROOT lexicon (this could be VerbRoot, NounRoot etc.)
           and ending in #. Each path is a sequence of lexc sublexicon
           entries.

           There will be one path for each surface form.

           For inflected forms of regular lexemes, our paths will look
           like this (here, for the example analysis and form
           aaba&#39;+VTA+Ind+Neg+Dub+0Pl+1Sg:aaba&#39;wigosiinaadogenan):

              LEXICON ROOT
              VTA:Prefix ;

              LEXICON VTA:Prefix
              @P.Prefix.NI@:@P.Prefix.NI@ni VTA:PrefixBoundary ;

              LEXICON VTA:PrefixBoundary
              0:%&lt;%&lt; VTA:PreElement ;

              LEXICON VTA:PreElement
              [PREVERB] VTA:Stems ;

              LEXICON VTA:Stems
              aaba&#39;:aaba&#39;w VTA:Class=VTA_C:Boundary ;

              LEXICON VTA:Class=VTA_C:Boundary
              0:%&gt;%&gt; VTA:Class=VTA_C:Flags ;

              LEXICON VTA:Class=VTA_C:Flags
              @R.Prefix.NI@ VTA:Class=VTA_C:Prefix=NI:Endings ;

              LEXICON VTA:Class=VTA_C:Prefix=NI:Endings
              +VTA+Ind+Neg+Dub+%0Pl+1Sg:igosiinaadogenan # ;

           For inflected forms of irregular lexemes, our pahts become
           very simple. We just enumerate the entire form as one
           chunk:

              LEXICON ROOT
              VTA:Irregular ;

              LEXICON VTA:Irregular
              izhi+VTA+Ind+Pos+Neu+%0Pl+1Sg:nindigonan # ;

        &#34;&#34;&#34;
        paths = []
        paradigm = self.paradigm
        klass = self.klass
        pre_tag = LexcPath.pre_element_tag
        for surface, parts in self.forms:
            if self.regular:
                p_prefix_flag, r_prefix_flag = LexcPath.__get_prefix_flags(parts.prefix)
                _, r_paradigm_flag = LexcPath.__get_paradigm_flags(paradigm)
                order, r_order_flag = self.__get_order_flag()
                prefix_id = &#34;NONE&#34; if parts.prefix == &#34;&#34; else parts.prefix.upper()
                # The following lexc sublexicon entries generate this form. 
                path = [
                    # @P.Prefix.&lt;X&gt;@_@P.Prefix.&lt;X&gt;@&lt;x&gt; &lt;Paradigm&gt;_PrefixBoundary ;
                    LexcEntry(f&#34;{paradigm}_Prefix&#34;,
                              p_prefix_flag,
                              p_prefix_flag+parts.prefix,
                              f&#34;{paradigm}_PrefixBoundary&#34;),
                    # 0_%&lt;%&lt; &lt;Paradigm&gt;_PreElement ;
                    LexcEntry(f&#34;{paradigm}_PrefixBoundary&#34;,
                              &#34;0&#34;,
                              escape(PREFIX_BOUNDARY),
                              self.conf[&#34;prefix_root&#34;]
                              if &#34;prefix_root&#34; in self.conf
                              else f&#34;{self.conf[&#39;pos&#39;]}Stems&#34;),
#                              f&#34;{paradigm}_PreElement&#34;),
                    # &lt;PreElement&gt; &lt;Paradigm&gt;_Stems ;
                    LexcEntry(f&#34;{self.conf[&#39;pos&#39;]}Stems&#34;,
                              r_paradigm_flag,
                              r_paradigm_flag,
                              f&#34;{paradigm}_Stems&#34;),
                    # &lt;lemma&gt;_&lt;stem&gt; &lt;Paradigm&gt;_Class=&lt;class&gt;_Boundary ;
                    LexcEntry(f&#34;{paradigm}_Stems&#34;,
                              self.lemma,
                              self.stem,
                              f&#34;{paradigm}_Class={klass}_Boundary&#34;),
                    # 0_%&gt;%&gt; &lt;Paradigm&gt;_Class=&lt;class&gt;_Flags ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Boundary&#34;,
                              &#34;0&#34;,
                              escape(SUFFIX_BOUNDARY),
                              f&#34;{paradigm}_Class={klass}_Flags&#34;),
                    # @R.Prefix.&lt;X&gt;@ &lt;Paradigm&gt;_Class=&lt;class&gt;_Prefix=&lt;X&gt;_Endings ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Flags&#34;,
                              r_prefix_flag,
                              r_prefix_flag,
                              f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}&#34;),
                    # @U.Order.&lt;Y&gt;@ &lt;Paradigm&gt;_Class=&lt;class&gt;_Prefix=&lt;X&gt;_Order=&lt;Y&gt;_Endings
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}&#34;,
                              r_order_flag,
                              r_order_flag,
                              f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}_Endings&#34;),
                    # &lt;tags&gt;_&lt;ending&gt; # ;
                    LexcEntry(f&#34;{paradigm}_Class={klass}_Prefix={prefix_id}_Order={order}_Endings&#34;,
                              &#34;&#34;.join(self.tags),
                              parts.suffix,
                              &#34;#&#34;)
                ]
                paths.append(path)
            else:
                # Irregular forms are treated as one chunk and simply enumerated.
                paths.append([LexcEntry(f&#34;{paradigm}_Irregular&#34;,
                                        f&#34;{self.lemma}{&#39;&#39;.join(self.tags)}&#34;,
                                        surface,
                                        &#34;#&#34;)])

        return paths

    def extend_lexicons(self, lexicons:dict) -&gt; None:
        &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
        def get_paradigm(s):
            return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
        for path in self.__get_lexc_paths():
            paradigm = get_paradigm(path[0].lexicon)
            p_paradigm_flag, _ = LexcPath.__get_paradigm_flags(paradigm)
            lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                      p_paradigm_flag,
                                                      p_paradigm_flag,
                                                      path[0].lexicon))
            for lexc_entry in path:
                if not lexc_entry.lexicon in lexicons:
                    lexicons[lexc_entry.lexicon] = set()
                lexicons[lexc_entry.lexicon].add(lexc_entry)
        
    def __str__(self):        
        paths = self.get_lexc_paths()
        res = &#34;&#34;
        for path in paths:
            for lexc_entry in path:
                res += f&#34;{lexc_entry}\n&#34;
            res += &#34;----\n&#34;
        return res

    def __hash__(self):
        return hash(str(self))</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.multichar_symbols"><code class="name">var <span class="ident">multichar_symbols</span> : set</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="csv2fst.lexc_path.LexcPath.pre_element_tag"><code class="name">var <span class="ident">pre_element_tag</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.update_multichar_symbol_set"><code class="name flex">
<span>def <span class="ident">update_multichar_symbol_set</span></span>(<span>conf: dict) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Must be called when the first LexcPath object is
initialized.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def update_multichar_symbol_set(cls, conf:dict) -&gt; None:
    &#34;&#34;&#34;Must be called when the first LexcPath object is
       initialized.&#34;&#34;&#34;
    cls.multichar_symbols.update(set(map(escape,conf[&#34;multichar_symbols&#34;])))
    #cls.pre_element_tag = escape(conf[&#34;pre_element_tag&#34;])
    cls.multichar_symbols.add(escape(PREFIX_BOUNDARY))
    cls.multichar_symbols.add(escape(SUFFIX_BOUNDARY))
    #cls.multichar_symbols.add(cls.pre_element_tag)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="csv2fst.lexc_path.LexcPath.extend_lexicons"><code class="name flex">
<span>def <span class="ident">extend_lexicons</span></span>(<span>self, lexicons: dict) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Add the lexc paths representing this path to lexicons.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extend_lexicons(self, lexicons:dict) -&gt; None:
    &#34;&#34;&#34;Add the lexc paths representing this path to lexicons.&#34;&#34;&#34;
    def get_paradigm(s):
        return re.sub(&#34;[_].*&#34;,&#34;&#34;,s)
    for path in self.__get_lexc_paths():
        paradigm = get_paradigm(path[0].lexicon)
        p_paradigm_flag, _ = LexcPath.__get_paradigm_flags(paradigm)
        lexicons[self.root_lexicon].add(LexcEntry(self.root_lexicon,
                                                  p_paradigm_flag,
                                                  p_paradigm_flag,
                                                  path[0].lexicon))
        for lexc_entry in path:
            if not lexc_entry.lexicon in lexicons:
                lexicons[lexc_entry.lexicon] = set()
            lexicons[lexc_entry.lexicon].add(lexc_entry)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="csv2fst.lexc_path.SplitForm"><code class="flex name class">
<span>class <span class="ident">SplitForm</span></span>
<span>(</span><span>prefix, stem, suffix)</span>
</code></dt>
<dd>
<div class="desc"><p>SplitForm(prefix, stem, suffix)</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.tuple</li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="csv2fst.lexc_path.SplitForm.prefix"><code class="name">var <span class="ident">prefix</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 0</p></div>
</dd>
<dt id="csv2fst.lexc_path.SplitForm.stem"><code class="name">var <span class="ident">stem</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 1</p></div>
</dd>
<dt id="csv2fst.lexc_path.SplitForm.suffix"><code class="name">var <span class="ident">suffix</span></code></dt>
<dd>
<div class="desc"><p>Alias for field number 2</p></div>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="csv2fst" href="index.html">csv2fst</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="csv2fst.lexc_path.entry2str" href="#csv2fst.lexc_path.entry2str">entry2str</a></code></li>
<li><code><a title="csv2fst.lexc_path.escape" href="#csv2fst.lexc_path.escape">escape</a></code></li>
<li><code><a title="csv2fst.lexc_path.split_form" href="#csv2fst.lexc_path.split_form">split_form</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="csv2fst.lexc_path.LexcEntry" href="#csv2fst.lexc_path.LexcEntry">LexcEntry</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.LexcEntry.analysis" href="#csv2fst.lexc_path.LexcEntry.analysis">analysis</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.lexicon" href="#csv2fst.lexc_path.LexcEntry.lexicon">lexicon</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.next_lexicon" href="#csv2fst.lexc_path.LexcEntry.next_lexicon">next_lexicon</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcEntry.surface" href="#csv2fst.lexc_path.LexcEntry.surface">surface</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="csv2fst.lexc_path.LexcPath" href="#csv2fst.lexc_path.LexcPath">LexcPath</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.LexcPath.extend_lexicons" href="#csv2fst.lexc_path.LexcPath.extend_lexicons">extend_lexicons</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.multichar_symbols" href="#csv2fst.lexc_path.LexcPath.multichar_symbols">multichar_symbols</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.pre_element_tag" href="#csv2fst.lexc_path.LexcPath.pre_element_tag">pre_element_tag</a></code></li>
<li><code><a title="csv2fst.lexc_path.LexcPath.update_multichar_symbol_set" href="#csv2fst.lexc_path.LexcPath.update_multichar_symbol_set">update_multichar_symbol_set</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="csv2fst.lexc_path.SplitForm" href="#csv2fst.lexc_path.SplitForm">SplitForm</a></code></h4>
<ul class="">
<li><code><a title="csv2fst.lexc_path.SplitForm.prefix" href="#csv2fst.lexc_path.SplitForm.prefix">prefix</a></code></li>
<li><code><a title="csv2fst.lexc_path.SplitForm.stem" href="#csv2fst.lexc_path.SplitForm.stem">stem</a></code></li>
<li><code><a title="csv2fst.lexc_path.SplitForm.suffix" href="#csv2fst.lexc_path.SplitForm.suffix">suffix</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>